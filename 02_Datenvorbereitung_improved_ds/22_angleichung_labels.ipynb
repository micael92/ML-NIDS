{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angleichung der Label Bezeichnungnen beider Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import logging\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Parameter\n",
    "logging.basicConfig(\n",
    "    filename='22_angleichung_labels.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Verzeichnis der original CSV-Dateien\n",
    "verzeichnis_ids17 = '../01_Datensaetze/improved_cic-ids-2017'\n",
    "verzeichnis_ids18 = '../01_Datensaetze/improved_cse-cic-ids-2018'\n",
    "verzeichnis_ids17_processed = '../01_Datensaetze/improved_cic-ids-2017/processed'\n",
    "verzeichnis_ids18_processed = '../01_Datensaetze/improved_cse-cic-ids-2018/processed'\n",
    "\n",
    "nrows = None\n",
    "chunksize = 1000000\n",
    "\n",
    "# Mapping von CICIDS2017-Bezeichnungen zu CICIDS2018-Bezeichnungen\n",
    "mapping_2017_to_2018 = {\n",
    "    'Botnet': 'Botnet Ares',\n",
    "    'Botnet - Attempted': 'Botnet Ares - Attempted',\n",
    "    'DDoS': 'DDoS-LOIC-HTTP',\n",
    "    'Infiltration - Portscan': 'Infiltration - NMAP Portscan',\n",
    "    'SSH-Patator': 'SSH-Bruteforce'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_file(verzeichnis, datei):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis, datei)\n",
    "        try:\n",
    "            df = pd.read_csv(pfad_zur_datei, nrows=nrows)\n",
    "            found_labels = df['Label'].unique()\n",
    "            logging.info(f\"Successfully read {pfad_zur_datei}. Found labels: {found_labels}\")\n",
    "            return found_labels\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading {pfad_zur_datei}: {e}\")\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def get_labels_from_dir(verzeichnis):\n",
    "    try:\n",
    "        logging.info(f\"Start processing directory {verzeichnis}\")\n",
    "        with mp.Pool(processes=2) as pool:\n",
    "            results = pool.starmap(get_labels_from_file, [(verzeichnis, datei) for datei in os.listdir(verzeichnis)])\n",
    "\n",
    "        labels = set()\n",
    "        for result in results:\n",
    "            labels.update(result)\n",
    "        \n",
    "        logging.info(f\"Successfully processed directory {verzeichnis}\")\n",
    "        return labels\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing directory {verzeichnis}: {e}\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels_ids17 \u001b[38;5;241m=\u001b[39m \u001b[43mget_labels_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverzeichnis_ids17\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mget_labels_from_dir\u001b[0;34m(verzeichnis)\u001b[0m\n\u001b[1;32m     16\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart processing directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mverzeichnis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 18\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_labels_from_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverzeichnis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatei\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdatei\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverzeichnis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels_ids17 = get_labels_from_dir(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ids18 = get_labels_from_dir(verzeichnis_ids18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BENIGN',\n",
       " 'Botnet Ares',\n",
       " 'Botnet Ares - Attempted',\n",
       " 'DDoS-LOIC-HTTP',\n",
       " 'DoS GoldenEye',\n",
       " 'DoS GoldenEye - Attempted',\n",
       " 'DoS Hulk',\n",
       " 'DoS Hulk - Attempted',\n",
       " 'DoS Slowloris',\n",
       " 'DoS Slowloris - Attempted',\n",
       " 'FTP-Patator - Attempted',\n",
       " 'Infiltration - NMAP Portscan',\n",
       " 'SSH-Bruteforce',\n",
       " 'Web Attack - Brute Force',\n",
       " 'Web Attack - Brute Force - Attempted',\n",
       " 'Web Attack - SQL Injection',\n",
       " 'Web Attack - SQL Injection - Attempted',\n",
       " 'Web Attack - XSS',\n",
       " 'Web Attack - XSS - Attempted'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ids17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ids18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ids17 == labels_ids18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Angriffe unterscheiden sich teilweise. Nach genauer Analyse werden die Datensätze aneinander angepasst. Dabei werden Angriffe entfernt, zusammengefasst oder Bezeichnungen angepasst. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anpassung der Bezeichnungen der Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um eine einzelne CSV-Datei zu verarbeiten und Labels zu ersetzen\n",
    "def relabel_file(file_path):\n",
    "    try:\n",
    "        # Lade die CSV-Datei in Chunks\n",
    "        chunks = pd.read_csv(file_path, chunksize=chunksize)\n",
    "\n",
    "        # Verarbeite jeden Chunk\n",
    "        for chunk in chunks:\n",
    "            # Prüfe, ob es eine Spalte mit den Angriffsnamen gibt (z.B. 'Label')\n",
    "            if 'Label' in chunk.columns:\n",
    "                # Ersetze die Labels basierend auf dem Mapping\n",
    "                chunk['Label'] = chunk['Label'].map(mapping_2017_to_2018).fillna(chunk['Label'])\n",
    "\n",
    "                # Speichere den Chunk mit den geänderten Labels zurück in die Originaldatei\n",
    "                chunk.to_csv(file_path, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                logging.warning(f\"Keine 'Label'-Spalte gefunden in {file_path}\")\n",
    "        \n",
    "        logging.info(f\"Datei verarbeitet und gespeichert: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fehler beim Verarbeiten der Datei {file_path}: {e}\")\n",
    "\n",
    "# Funktion, um alle CSV-Dateien im Verzeichnis zu finden und zu verarbeiten\n",
    "def process_all_files_in_directory(directory):\n",
    "    # Hole alle CSV-Dateien im Verzeichnis\n",
    "    csv_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Nutze Multiprocessing, um die Dateien parallel zu verarbeiten\n",
    "    with mp.Pool(processes=4) as pool:\n",
    "        pool.map(relabel_file, csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_all_files_in_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverzeichnis_ids17\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Bezeichnungen in den Dateien von CICIDS2017 werden an die Bezeichnungen von CICIDS2018 angepasst\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m, in \u001b[0;36mprocess_all_files_in_directory\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Nutze Multiprocessing, um die Dateien parallel zu verarbeiten\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelabel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_all_files_in_directory(verzeichnis_ids17) #Bezeichnungen in den Dateien von CICIDS2017 werden an die Bezeichnungen von CICIDS2018 angepasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels_ids17 = get_labels_from_dir(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bezeichnungen sind angepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angriffe entfernen, die nicht in beiden Datensätzen vorhanden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_in_ids17 = ['DoS Slowhttptest', 'DoS Slowhttptest - Attempted', 'FTP-Patator', 'Heartbleed', 'Infiltration', 'Infiltration - Attempted', 'Portscan', 'SSH-Patator - Attempted']\n",
    "remove_in_ids18 = ['DDoS-HOIC', 'DDoS-LOIC-UDP', 'DDoS-LOIC-UDP - Attempted', 'Infiltration - Communication Victim Attacker', 'Infiltration - Dropbox Download', 'Infiltration - Dropbox Download - Attempted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_labels(file_path, labels_to_remove, output_file_path):\n",
    "    try:\n",
    "        # Lade die CSV-Datei in Chunks\n",
    "        chunks = pd.read_csv(file_path, chunksize=chunksize)\n",
    "\n",
    "        # Verarbeite jeden Chunk\n",
    "        for chunk in chunks:\n",
    "            # Entferne die Zeilen mit den angegebenen Labels\n",
    "            chunk = chunk[~chunk['Label'].isin(labels_to_remove)]\n",
    "\n",
    "            # Speichere den Chunk ohne die entfernten Zeilen in die neue Datei\n",
    "            chunk.to_csv(output_file_path, mode='a', header=not os.path.exists(output_file_path), index=False)\n",
    "        \n",
    "        logging.info(f\"Zeilen mit Labels '{labels_to_remove}' entfernt und Datei gespeichert: {output_file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fehler beim Verarbeiten der Datei {file_path}: {e}\")\n",
    "\n",
    "def remove_labels_from_all_files(directory, labels_to_remove):\n",
    "    # Hole alle CSV-Dateien im Verzeichnis\n",
    "    csv_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Nutze Multiprocessing, um die Dateien parallel zu verarbeiten\n",
    "    with mp.Pool(processes=4) as pool:\n",
    "        pool.starmap(remove_rows_with_labels, [(file, labels_to_remove, f\"{file}_processed.csv\") for file in csv_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_labels_from_all_files(verzeichnis_ids17, remove_in_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels_ids17 = get_labels_from_dir(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BENIGN',\n",
       " 'Botnet Ares',\n",
       " 'Botnet Ares - Attempted',\n",
       " 'DDoS-LOIC-HTTP',\n",
       " 'DoS GoldenEye',\n",
       " 'DoS GoldenEye - Attempted',\n",
       " 'DoS Hulk',\n",
       " 'DoS Hulk - Attempted',\n",
       " 'DoS Slowloris',\n",
       " 'DoS Slowloris - Attempted',\n",
       " 'FTP-Patator - Attempted',\n",
       " 'Infiltration - NMAP Portscan',\n",
       " 'SSH-Bruteforce',\n",
       " 'Web Attack - Brute Force',\n",
       " 'Web Attack - Brute Force - Attempted',\n",
       " 'Web Attack - SQL Injection',\n",
       " 'Web Attack - SQL Injection - Attempted',\n",
       " 'Web Attack - XSS',\n",
       " 'Web Attack - XSS - Attempted'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels_ids17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_labels_from_all_files(verzeichnis_ids18, remove_in_ids18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels_ids18 = get_labels_from_dir(verzeichnis_ids18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
