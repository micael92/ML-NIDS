{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angleichung der Spalten beider Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Parameter\n",
    "logging.basicConfig(\n",
    "    filename='21_angleichung_spalten.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Verzeichnis der CSV-Dateien\n",
    "verzeichnis_ids17 = '../01_Datensaetze/improved_cic-ids-2017'\n",
    "verzeichnis_ids18 = '../01_Datensaetze/improved_cse-cic-ids-2018'\n",
    "nrows = 5 # None = alle Zeilen, ansonsten Anzahl der Zeilen für Testzwecke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entpacken der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../01_Datensaetze/improved_cic-ids-2017/CICIDS2017_improved.zip\n",
      "  inflating: ../01_Datensaetze/improved_cic-ids-2017/friday.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cic-ids-2017/monday.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cic-ids-2017/thursday.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cic-ids-2017/tuesday.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cic-ids-2017/wednesday.csv  \n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "!rm -r ../01_Datensaetze/improved_cic-ids-2017/*.csv\n",
    "!unzip -o ../01_Datensaetze/improved_cic-ids-2017/CICIDS2017_improved.zip -d ../01_Datensaetze/improved_cic-ids-2017/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../01_Datensaetze/improved_cse-cic-ids-2018/CSECICIDS2018_improved.zip\n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-14-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Friday-16-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Tuesday-20-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-21-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-22-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Friday-23-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-28-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-01-03-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-15-02-2018.csv  \n",
      "  inflating: ../01_Datensaetze/improved_cse-cic-ids-2018/Friday-02-03-2018.csv  \n"
     ]
    }
   ],
   "source": [
    "# ids18\n",
    "!rm -r ../01_Datensaetze/improved_cse-cic-ids-2018/*.csv\n",
    "!unzip -o ../01_Datensaetze/improved_cse-cic-ids-2018/CSECICIDS2018_improved.zip -d ../01_Datensaetze/improved_cse-cic-ids-2018/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prüfen der Spalten beider Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_columns(file):\n",
    "    df = pd.read_csv(file, nrows=1)\n",
    "    return {file:df.shape[1]}\n",
    "\n",
    "def count_columns_in_directory(directory):\n",
    "    try:\n",
    "        logging.info(f\"Start counting columns in directory {directory}\")\n",
    "        with mp.Pool(processes=5) as pool:\n",
    "            result = pool.map(count_columns, [os.path.join(directory, datei) for datei in os.listdir(directory) if datei.endswith('.csv')])\n",
    "\n",
    "        logging.info(f\"Successfully counted columns in directory {directory}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error counting columns in directory {directory}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'../01_Datensaetze/improved_cic-ids-2017/tuesday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/wednesday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/friday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/monday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/thursday.csv': 84}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_columns_in_directory(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'../01_Datensaetze/improved_cse-cic-ids-2018/Tuesday-20-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-15-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-01-03-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Thursday-22-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-21-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-14-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Friday-23-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Friday-16-02-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Friday-02-03-2018.csv': 84},\n",
       " {'../01_Datensaetze/improved_cse-cic-ids-2018/Wednesday-28-02-2018.csv': 84}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_columns_in_directory(verzeichnis_ids18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zu den originalen Datensätzen passt hier die Spaltenanzahl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angleichung der Spaltenbezeichnung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst prüfen, ob alle Header in den verschiedenen Dateien eines Datensatzes gleich sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Elemente und somit alle Header in ids17 sind gleich: True\n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "ids17_col_hash = []\n",
    "for datei in os.listdir(verzeichnis_ids17):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids17, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=nrows, skipinitialspace=True)\n",
    "        ids17_col_hash.append(hash(tuple(df.columns)))\n",
    "\n",
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Elemente und somit alle Header in ids17 sind gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids17_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Elemente und somit alle Header in ids18 sind gleich: True\n"
     ]
    }
   ],
   "source": [
    "ids18_col_hash = []\n",
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=nrows)\n",
    "        ids18_col_hash.append(hash(tuple(df.columns)))\n",
    "\n",
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Elemente und somit alle Header in ids18 sind gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids18_columns = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prüfen, ob die Spaltennamen in beiden Datensätzen gleich sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Spalten sind gleich:                 Dst Port\n",
      "Die Spalten sind gleich:                 Protocol\n",
      "Die Spalten sind gleich:                 Flow Duration\n",
      "Die Spalten sind gleich:                 Total Fwd Packet\n",
      "Die Spalten sind gleich:                 Total Bwd packets\n",
      "Die Spalten sind gleich:                 Total Length of Fwd Packet\n",
      "Die Spalten sind gleich:                 Total Length of Bwd Packet\n",
      "Die Spalten sind gleich:                 Fwd Packet Length Max\n",
      "Die Spalten sind gleich:                 Fwd Packet Length Min\n",
      "Die Spalten sind gleich:                 Fwd Packet Length Mean\n",
      "Die Spalten sind gleich:                 Fwd Packet Length Std\n",
      "Die Spalten sind gleich:                 Bwd Packet Length Max\n",
      "Die Spalten sind gleich:                 Bwd Packet Length Min\n",
      "Die Spalten sind gleich:                 Bwd Packet Length Mean\n",
      "Die Spalten sind gleich:                 Bwd Packet Length Std\n",
      "Die Spalten sind gleich:                 Flow Bytes/s\n",
      "Die Spalten sind gleich:                 Flow Packets/s\n",
      "Die Spalten sind gleich:                 Flow IAT Mean\n",
      "Die Spalten sind gleich:                 Flow IAT Std\n",
      "Die Spalten sind gleich:                 Flow IAT Max\n",
      "Die Spalten sind gleich:                 Flow IAT Min\n",
      "Die Spalten sind gleich:                 Fwd IAT Total\n",
      "Die Spalten sind gleich:                 Fwd IAT Mean\n",
      "Die Spalten sind gleich:                 Fwd IAT Std\n",
      "Die Spalten sind gleich:                 Fwd IAT Max\n",
      "Die Spalten sind gleich:                 Fwd IAT Min\n",
      "Die Spalten sind gleich:                 Bwd IAT Total\n",
      "Die Spalten sind gleich:                 Bwd IAT Mean\n",
      "Die Spalten sind gleich:                 Bwd IAT Std\n",
      "Die Spalten sind gleich:                 Bwd IAT Max\n",
      "Die Spalten sind gleich:                 Bwd IAT Min\n",
      "Die Spalten sind gleich:                 Fwd PSH Flags\n",
      "Die Spalten sind gleich:                 Bwd PSH Flags\n",
      "Die Spalten sind gleich:                 Fwd URG Flags\n",
      "Die Spalten sind gleich:                 Bwd URG Flags\n",
      "Die Spalten sind gleich:                 Fwd RST Flags\n",
      "Die Spalten sind gleich:                 Bwd RST Flags\n",
      "Die Spalten sind gleich:                 Fwd Header Length\n",
      "Die Spalten sind gleich:                 Bwd Header Length\n",
      "Die Spalten sind gleich:                 Fwd Packets/s\n",
      "Die Spalten sind gleich:                 Bwd Packets/s\n",
      "Die Spalten sind gleich:                 Packet Length Min\n",
      "Die Spalten sind gleich:                 Packet Length Max\n",
      "Die Spalten sind gleich:                 Packet Length Mean\n",
      "Die Spalten sind gleich:                 Packet Length Std\n",
      "Die Spalten sind gleich:                 Packet Length Variance\n",
      "Die Spalten sind gleich:                 FIN Flag Count\n",
      "Die Spalten sind gleich:                 SYN Flag Count\n",
      "Die Spalten sind gleich:                 RST Flag Count\n",
      "Die Spalten sind gleich:                 PSH Flag Count\n",
      "Die Spalten sind gleich:                 ACK Flag Count\n",
      "Die Spalten sind gleich:                 URG Flag Count\n",
      "Die Spalten sind gleich:                 CWR Flag Count\n",
      "Die Spalten sind gleich:                 ECE Flag Count\n",
      "Die Spalten sind gleich:                 Down/Up Ratio\n",
      "Die Spalten sind gleich:                 Average Packet Size\n",
      "Die Spalten sind gleich:                 Fwd Segment Size Avg\n",
      "Die Spalten sind gleich:                 Bwd Segment Size Avg\n",
      "Die Spalten sind gleich:                 Fwd Bytes/Bulk Avg\n",
      "Die Spalten sind gleich:                 Fwd Packet/Bulk Avg\n",
      "Die Spalten sind gleich:                 Fwd Bulk Rate Avg\n",
      "Die Spalten sind gleich:                 Bwd Bytes/Bulk Avg\n",
      "Die Spalten sind gleich:                 Bwd Packet/Bulk Avg\n",
      "Die Spalten sind gleich:                 Bwd Bulk Rate Avg\n",
      "Die Spalten sind gleich:                 Subflow Fwd Packets\n",
      "Die Spalten sind gleich:                 Subflow Fwd Bytes\n",
      "Die Spalten sind gleich:                 Subflow Bwd Packets\n",
      "Die Spalten sind gleich:                 Subflow Bwd Bytes\n",
      "Die Spalten sind gleich:                 FWD Init Win Bytes\n",
      "Die Spalten sind gleich:                 Bwd Init Win Bytes\n",
      "Die Spalten sind gleich:                 Fwd Act Data Pkts\n",
      "Die Spalten sind gleich:                 Fwd Seg Size Min\n",
      "Die Spalten sind gleich:                 Active Mean\n",
      "Die Spalten sind gleich:                 Active Std\n",
      "Die Spalten sind gleich:                 Active Max\n",
      "Die Spalten sind gleich:                 Active Min\n",
      "Die Spalten sind gleich:                 Idle Mean\n",
      "Die Spalten sind gleich:                 Idle Std\n",
      "Die Spalten sind gleich:                 Idle Max\n",
      "Die Spalten sind gleich:                 Idle Min\n",
      "Die Spalten sind gleich:                 ICMP Code\n",
      "Die Spalten sind gleich:                 ICMP Type\n",
      "Die Spalten sind gleich:                 Total TCP Flow Time\n",
      "Die Spalten sind gleich:                 Label\n"
     ]
    }
   ],
   "source": [
    "# Element für Element Vergleich\n",
    "for col17, col18 in zip(ids17_columns, ids18_columns):\n",
    "    if col17 == col18:\n",
    "        print(f\"Die Spalten sind gleich:\".ljust(40), f'{col17}')\n",
    "    else:\n",
    "        print(f\"Die Spalten sind unterschiedlich:\".ljust(40), f\"{col17} != {col18}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da sich die Bezeichnung der Spalten zwischen ids17 und ids18 nicht wie in den originalen Datensätzen unterscheidet muss keine Anpassung erfolgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Header in ids17 und ids18 sind jetzt gleich: True\n"
     ]
    }
   ],
   "source": [
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Header in ids17 und ids18 sind jetzt gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids17_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entfernen nicht relevanter Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Timestamp', 'Attempted Category']\n",
    "\n",
    "def remove_columns_from_file(file_path):\n",
    "    temp_file = file_path + '.tmp'\n",
    "    try:\n",
    "        # Lade die CSV-Datei in Chunks\n",
    "        chunksize = 500000  # Optional: Anpassbare Chunk-Größe\n",
    "        chunks = pd.read_csv(file_path, chunksize=chunksize)\n",
    "\n",
    "        # Verarbeite jeden Chunk und speichere in eine temporäre Datei\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Entferne die spezifischen Spalten, falls sie vorhanden sind\n",
    "            chunk = chunk.drop(columns=[col for col in columns_to_remove if col in chunk.columns], errors='ignore')\n",
    "\n",
    "            # Speichere den Chunk in die temporäre Datei\n",
    "            if i == 0:\n",
    "                chunk.to_csv(temp_file, mode='w', header=True, index=False)\n",
    "            else:\n",
    "                chunk.to_csv(temp_file, mode='a', header=False, index=False)\n",
    "\n",
    "        # Ersetze die Originaldatei durch die temporäre Datei\n",
    "        os.replace(temp_file, file_path)\n",
    "\n",
    "        logging.info(f\"Datei verarbeitet und gespeichert: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fehler beim Verarbeiten der Datei {file_path}: {e}\")\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)  # Entferne die temporäre Datei im Fehlerfall\n",
    "\n",
    "def remove_columns_from_directory(directory):\n",
    "    try:\n",
    "        logging.info(f\"Start processing directory {directory}\")\n",
    "        with mp.Pool(processes=5) as pool:\n",
    "            pool.map(remove_columns_from_file, [os.path.join(directory, datei) for datei in os.listdir(directory) if datei.endswith('.csv')])\n",
    "\n",
    "        logging.info(f\"Successfully processed directory {directory}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing directory {directory}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns_from_directory(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'../01_Datensaetze/improved_cic-ids-2017/tuesday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/wednesday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/friday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/monday.csv': 84},\n",
       " {'../01_Datensaetze/improved_cic-ids-2017/thursday.csv': 84}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_columns_in_directory(verzeichnis_ids17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns_from_directory(verzeichnis_ids18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: Tuesday-20-02-2018.csv                                       \tAnzahl der Spalten: 84\n",
      "Datei: Thursday-15-02-2018.csv                                      \tAnzahl der Spalten: 84\n",
      "Datei: Thursday-01-03-2018.csv                                      \tAnzahl der Spalten: 84\n",
      "Datei: Thursday-22-02-2018.csv                                      \tAnzahl der Spalten: 84\n",
      "Datei: Wednesday-21-02-2018.csv                                     \tAnzahl der Spalten: 84\n",
      "Datei: Wednesday-14-02-2018.csv                                     \tAnzahl der Spalten: 84\n",
      "Datei: Friday-23-02-2018.csv                                        \tAnzahl der Spalten: 84\n",
      "Datei: Friday-16-02-2018.csv                                        \tAnzahl der Spalten: 84\n",
      "Datei: Friday-02-03-2018.csv                                        \tAnzahl der Spalten: 84\n",
      "Datei: Wednesday-28-02-2018.csv                                     \tAnzahl der Spalten: 84\n"
     ]
    }
   ],
   "source": [
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=2)\n",
    "        print(f\"Datei: {datei.ljust(60)}\", f\"\\tAnzahl der Spalten:\", len(df.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
