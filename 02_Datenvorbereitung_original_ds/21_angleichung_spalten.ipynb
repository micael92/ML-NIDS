{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angleichung der Spalten beider Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "verzeichnis_ids17 = '../01_Datensaetze/cic-ids-2017/CSV'\n",
    "verzeichnis_ids18 = '../01_Datensaetze/cse-cic-ids2018/CSV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entpacken der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../01_Datensaetze/cic-ids-2017/original/MachineLearningCSV.zip\n",
      "   creating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/\n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv  \n",
      "  inflating: ../01_Datensaetze/cic-ids-2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv  \n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "!unzip -o ../01_Datensaetze/cic-ids-2017/original/MachineLearningCSV.zip -d ../01_Datensaetze/cic-ids-2017\n",
    "!rm -r ../01_Datensaetze/cic-ids-2017/CSV\n",
    "!mv ../01_Datensaetze/cic-ids-2017/MachineLearningCVE ../01_Datensaetze/cic-ids-2017/CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids18 muss aufgrund der Größe manuell entpackt und in das Zielverzeichnis verschoben werden\n",
    "!rm ../01_Datensaetze/cse-cic-ids2018/CSV/*\n",
    "!cp /mnt/d/cicids2018/Processed\\ Traffic\\ Data\\ for\\ ML\\ Algorithms/*.csv ../01_Datensaetze/cse-cic-ids2018/CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prüfen der Spalten beider Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: Friday-WorkingHours-Morning.pcap_ISCX.csv                    \tAnzahl der Spalten: 79\n",
      "Datei: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv         \tAnzahl der Spalten: 79\n",
      "Datei: Wednesday-workingHours.pcap_ISCX.csv                         \tAnzahl der Spalten: 79\n",
      "Datei: Monday-WorkingHours.pcap_ISCX.csv                            \tAnzahl der Spalten: 79\n",
      "Datei: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv             \tAnzahl der Spalten: 79\n",
      "Datei: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  \tAnzahl der Spalten: 79\n",
      "Datei: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv       \tAnzahl der Spalten: 79\n",
      "Datei: Tuesday-WorkingHours.pcap_ISCX.csv                           \tAnzahl der Spalten: 79\n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "for datei in os.listdir(verzeichnis_ids17):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids17, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=1)\n",
    "        print(f\"Datei: {datei.ljust(60)}\", f\"\\tAnzahl der Spalten:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv  \tAnzahl der Spalten: 80\n",
      "Datei: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv \tAnzahl der Spalten: 80\n",
      "Datei: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv    \tAnzahl der Spalten: 80\n",
      "Datei: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv \tAnzahl der Spalten: 80\n",
      "Datei: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv \tAnzahl der Spalten: 80\n",
      "Datei: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv  \tAnzahl der Spalten: 80\n",
      "Datei: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv    \tAnzahl der Spalten: 80\n",
      "Datei: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv  \tAnzahl der Spalten: 84\n",
      "Datei: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv    \tAnzahl der Spalten: 80\n",
      "Datei: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv  \tAnzahl der Spalten: 80\n"
     ]
    }
   ],
   "source": [
    "# ids18\n",
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=1)\n",
    "        print(f\"Datei: {datei.ljust(50)}\", f\"\\tAnzahl der Spalten:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datensätze haben eine unterschiedliche Anzahl an Spalten. Ids17 enthält die Spalte **\"Fwd_Header_Length\"** doppelt. Ids18 enthält die nicht relevanten und in ids17 nicht vorhandenen Spalten **Protocol** und **Timestamp**. Folgend werden die Spalten angepasst, sodass beide Datensätze die gleichen Spalten enthalten. Außerdem wird die Bennenung der Spalten zwischen den Datensätzen vereinheitlicht, da diese in den Datensätzen leicht abweicht. In ids17 werden zusätzlich überflüssige Leerzeichen in der Spaltenbezeichnung entfernt.\n",
    "\n",
    "ids17\n",
    "- Spalte **\"Fwd_Header_Length\"** doppelt\n",
    "- Überflüssige Leerzeichen in Spaltenbezeichnung\n",
    "\n",
    "ids18\n",
    "- Spalten **Protocol** und **Timestamp** inkompatibel zu ids17\n",
    "- In Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv weitere überflüssige Spalten **Flow ID,Src IP,Src Port,Dst IP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angleichung der Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n",
      "Doppelte Spalte: Fwd Header Length Fwd Header Length.1\n",
      "--> Doppelte Spalte entfernt. Neue Spaltenanzahl: 78\n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "for datei in os.listdir(verzeichnis_ids17):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids17, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=4, skipinitialspace=True)\n",
    "        if df.columns[34] == df.columns[55][:-2]:\n",
    "            print(f'Doppelte Spalte:', df.columns[34], df.columns[55])\n",
    "            df.drop(df.columns[55], axis=1, inplace=True)\n",
    "            df.to_csv(pfad_zur_datei, index=False)\n",
    "            print(f'--> Doppelte Spalte entfernt. Neue Spaltenanzahl:', len(df.columns))\n",
    "        else:\n",
    "            print(f'Keine doppelten Spalten:', df.columns[34], df.columns[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv  \tNeue Anzahl der Spalten: 78\n",
      "Datei: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv \tNeue Anzahl der Spalten: 78\n",
      "Datei: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv    \tNeue Anzahl der Spalten: 78\n",
      "Datei: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv \tNeue Anzahl der Spalten: 78\n",
      "Datei: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv \tNeue Anzahl der Spalten: 78\n",
      "Datei: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv  \tNeue Anzahl der Spalten: 78\n",
      "Datei: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv    \tNeue Anzahl der Spalten: 78\n",
      "Datei: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv  \tNeue Anzahl der Spalten: 78\n",
      "Datei: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv    \tNeue Anzahl der Spalten: 78\n",
      "Datei: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv  \tNeue Anzahl der Spalten: 78\n"
     ]
    }
   ],
   "source": [
    "# ids18\n",
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=5)\n",
    "        if len(df.columns) == 80:\n",
    "            df.drop(['Protocol','Timestamp'], axis=1, inplace=True)\n",
    "            print(f\"Datei: {datei.ljust(50)}\", f\"\\tNeue Anzahl der Spalten:\", len(df.columns))\n",
    "            df.to_csv(pfad_zur_datei, index=False)\n",
    "        elif datei == 'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv' and len(df.columns) == 84:\n",
    "            df.drop(['Flow ID','Src IP','Src Port','Dst IP','Protocol','Timestamp'], axis=1, inplace=True)\n",
    "            print(f\"Datei: {datei.ljust(50)}\", f\"\\tNeue Anzahl der Spalten:\", len(df.columns))\n",
    "            df.to_csv(pfad_zur_datei, index=False)\n",
    "        else:\n",
    "            print(f\" {datei.ljust(55)} Keine Änderungen notwendig.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angleichung der Spaltenbezeichnung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst prüfen, ob alle Header in den verschiedenen Dateien eines Datensatzes gleich sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Elemente und somit alle Header in ids17 sind gleich: True\n"
     ]
    }
   ],
   "source": [
    "# ids17\n",
    "ids17_col_hash = []\n",
    "for datei in os.listdir(verzeichnis_ids17):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids17, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=4, skipinitialspace=True)\n",
    "        ids17_col_hash.append(hash(tuple(df.columns)))\n",
    "\n",
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Elemente und somit alle Header in ids17 sind gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids17_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Elemente und somit alle Header in ids18 sind gleich: True\n"
     ]
    }
   ],
   "source": [
    "ids18_col_hash = []\n",
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=5)\n",
    "        ids18_col_hash.append(hash(tuple(df.columns)))\n",
    "\n",
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Elemente und somit alle Header in ids18 sind gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids18_columns = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prüfen, ob die Spaltennamen in beiden Datensätzen gleich sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Spalten sind unterschiedlich:        Destination Port != Dst Port\n",
      "Die Spalten sind gleich:                 Flow Duration\n",
      "Die Spalten sind unterschiedlich:        Total Fwd Packets != Tot Fwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Total Backward Packets != Tot Bwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Total Length of Fwd Packets != TotLen Fwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Total Length of Bwd Packets != TotLen Bwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Fwd Packet Length Max != Fwd Pkt Len Max\n",
      "Die Spalten sind unterschiedlich:        Fwd Packet Length Min != Fwd Pkt Len Min\n",
      "Die Spalten sind unterschiedlich:        Fwd Packet Length Mean != Fwd Pkt Len Mean\n",
      "Die Spalten sind unterschiedlich:        Fwd Packet Length Std != Fwd Pkt Len Std\n",
      "Die Spalten sind unterschiedlich:        Bwd Packet Length Max != Bwd Pkt Len Max\n",
      "Die Spalten sind unterschiedlich:        Bwd Packet Length Min != Bwd Pkt Len Min\n",
      "Die Spalten sind unterschiedlich:        Bwd Packet Length Mean != Bwd Pkt Len Mean\n",
      "Die Spalten sind unterschiedlich:        Bwd Packet Length Std != Bwd Pkt Len Std\n",
      "Die Spalten sind unterschiedlich:        Flow Bytes/s != Flow Byts/s\n",
      "Die Spalten sind unterschiedlich:        Flow Packets/s != Flow Pkts/s\n",
      "Die Spalten sind gleich:                 Flow IAT Mean\n",
      "Die Spalten sind gleich:                 Flow IAT Std\n",
      "Die Spalten sind gleich:                 Flow IAT Max\n",
      "Die Spalten sind gleich:                 Flow IAT Min\n",
      "Die Spalten sind unterschiedlich:        Fwd IAT Total != Fwd IAT Tot\n",
      "Die Spalten sind gleich:                 Fwd IAT Mean\n",
      "Die Spalten sind gleich:                 Fwd IAT Std\n",
      "Die Spalten sind gleich:                 Fwd IAT Max\n",
      "Die Spalten sind gleich:                 Fwd IAT Min\n",
      "Die Spalten sind unterschiedlich:        Bwd IAT Total != Bwd IAT Tot\n",
      "Die Spalten sind gleich:                 Bwd IAT Mean\n",
      "Die Spalten sind gleich:                 Bwd IAT Std\n",
      "Die Spalten sind gleich:                 Bwd IAT Max\n",
      "Die Spalten sind gleich:                 Bwd IAT Min\n",
      "Die Spalten sind gleich:                 Fwd PSH Flags\n",
      "Die Spalten sind gleich:                 Bwd PSH Flags\n",
      "Die Spalten sind gleich:                 Fwd URG Flags\n",
      "Die Spalten sind gleich:                 Bwd URG Flags\n",
      "Die Spalten sind unterschiedlich:        Fwd Header Length != Fwd Header Len\n",
      "Die Spalten sind unterschiedlich:        Bwd Header Length != Bwd Header Len\n",
      "Die Spalten sind unterschiedlich:        Fwd Packets/s != Fwd Pkts/s\n",
      "Die Spalten sind unterschiedlich:        Bwd Packets/s != Bwd Pkts/s\n",
      "Die Spalten sind unterschiedlich:        Min Packet Length != Pkt Len Min\n",
      "Die Spalten sind unterschiedlich:        Max Packet Length != Pkt Len Max\n",
      "Die Spalten sind unterschiedlich:        Packet Length Mean != Pkt Len Mean\n",
      "Die Spalten sind unterschiedlich:        Packet Length Std != Pkt Len Std\n",
      "Die Spalten sind unterschiedlich:        Packet Length Variance != Pkt Len Var\n",
      "Die Spalten sind unterschiedlich:        FIN Flag Count != FIN Flag Cnt\n",
      "Die Spalten sind unterschiedlich:        SYN Flag Count != SYN Flag Cnt\n",
      "Die Spalten sind unterschiedlich:        RST Flag Count != RST Flag Cnt\n",
      "Die Spalten sind unterschiedlich:        PSH Flag Count != PSH Flag Cnt\n",
      "Die Spalten sind unterschiedlich:        ACK Flag Count != ACK Flag Cnt\n",
      "Die Spalten sind unterschiedlich:        URG Flag Count != URG Flag Cnt\n",
      "Die Spalten sind gleich:                 CWE Flag Count\n",
      "Die Spalten sind unterschiedlich:        ECE Flag Count != ECE Flag Cnt\n",
      "Die Spalten sind gleich:                 Down/Up Ratio\n",
      "Die Spalten sind unterschiedlich:        Average Packet Size != Pkt Size Avg\n",
      "Die Spalten sind unterschiedlich:        Avg Fwd Segment Size != Fwd Seg Size Avg\n",
      "Die Spalten sind unterschiedlich:        Avg Bwd Segment Size != Bwd Seg Size Avg\n",
      "Die Spalten sind unterschiedlich:        Fwd Avg Bytes/Bulk != Fwd Byts/b Avg\n",
      "Die Spalten sind unterschiedlich:        Fwd Avg Packets/Bulk != Fwd Pkts/b Avg\n",
      "Die Spalten sind unterschiedlich:        Fwd Avg Bulk Rate != Fwd Blk Rate Avg\n",
      "Die Spalten sind unterschiedlich:        Bwd Avg Bytes/Bulk != Bwd Byts/b Avg\n",
      "Die Spalten sind unterschiedlich:        Bwd Avg Packets/Bulk != Bwd Pkts/b Avg\n",
      "Die Spalten sind unterschiedlich:        Bwd Avg Bulk Rate != Bwd Blk Rate Avg\n",
      "Die Spalten sind unterschiedlich:        Subflow Fwd Packets != Subflow Fwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Subflow Fwd Bytes != Subflow Fwd Byts\n",
      "Die Spalten sind unterschiedlich:        Subflow Bwd Packets != Subflow Bwd Pkts\n",
      "Die Spalten sind unterschiedlich:        Subflow Bwd Bytes != Subflow Bwd Byts\n",
      "Die Spalten sind unterschiedlich:        Init_Win_bytes_forward != Init Fwd Win Byts\n",
      "Die Spalten sind unterschiedlich:        Init_Win_bytes_backward != Init Bwd Win Byts\n",
      "Die Spalten sind unterschiedlich:        act_data_pkt_fwd != Fwd Act Data Pkts\n",
      "Die Spalten sind unterschiedlich:        min_seg_size_forward != Fwd Seg Size Min\n",
      "Die Spalten sind gleich:                 Active Mean\n",
      "Die Spalten sind gleich:                 Active Std\n",
      "Die Spalten sind gleich:                 Active Max\n",
      "Die Spalten sind gleich:                 Active Min\n",
      "Die Spalten sind gleich:                 Idle Mean\n",
      "Die Spalten sind gleich:                 Idle Std\n",
      "Die Spalten sind gleich:                 Idle Max\n",
      "Die Spalten sind gleich:                 Idle Min\n",
      "Die Spalten sind gleich:                 Label\n"
     ]
    }
   ],
   "source": [
    "# Element für Element Vergleich\n",
    "for col17, col18 in zip(ids17_columns, ids18_columns):\n",
    "    if col17 == col18:\n",
    "        print(f\"Die Spalten sind gleich:\".ljust(40), f'{col17}')\n",
    "    else:\n",
    "        print(f\"Die Spalten sind unterschiedlich:\".ljust(40), f\"{col17} != {col18}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da sich die Bezeichnung der Spalten zwischen ids17 und ids18 unterscheidet, werden folgend die Bezeichnungen von ids17 für ids18 übernommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv  \tSpaltenbezeichnung angepasst.\n",
      "Datei: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv \tSpaltenbezeichnung angepasst.\n",
      "Datei: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv    \tSpaltenbezeichnung angepasst.\n",
      "Datei: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv \tSpaltenbezeichnung angepasst.\n",
      "Datei: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv \tSpaltenbezeichnung angepasst.\n",
      "Datei: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv  \tSpaltenbezeichnung angepasst.\n",
      "Datei: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv    \tSpaltenbezeichnung angepasst.\n",
      "Datei: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv  \tSpaltenbezeichnung angepasst.\n",
      "Datei: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv    \tSpaltenbezeichnung angepasst.\n",
      "Datei: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv  \tSpaltenbezeichnung angepasst.\n"
     ]
    }
   ],
   "source": [
    "for datei in os.listdir(verzeichnis_ids18):\n",
    "    if datei.endswith('.csv'):\n",
    "        pfad_zur_datei = os.path.join(verzeichnis_ids18, datei)\n",
    "        df = pd.read_csv(pfad_zur_datei, nrows=5)\n",
    "        df.columns = ids17_columns\n",
    "        df.to_csv(pfad_zur_datei, index=False)\n",
    "\n",
    "        ids17_col_hash.append(hash(tuple(df.columns)))\n",
    "        print(f\"Datei: {datei.ljust(50)}\", f\"\\tSpaltenbezeichnung angepasst.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prüfen ob jetzt alle Dateien beider Datensätze die gleiche Spaltenbezeichnung haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Header in ids17 und ids18 sind jetzt gleich: True\n"
     ]
    }
   ],
   "source": [
    "# Prüfen, ob alle Elemente in der Liste gleich sind\n",
    "all_equal = all(x == ids17_col_hash[0] for x in ids17_col_hash)\n",
    "print(f'Alle Header in ids17 und ids18 sind jetzt gleich:', all_equal)  \n",
    "\n",
    "if all_equal:\n",
    "    ids17_columns = df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
