{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "Training auf IDS18 80%  \n",
    "Validierung auf IDS18 10%   \n",
    "Test auf IDS18 10%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximale Zeilen und Spalten anzeigen\n",
    "pd.set_option('display.max_rows', None)  # Zeilen\n",
    "pd.set_option('display.max_columns', None)  # Spalten\n",
    "\n",
    "# Logging Parameter\n",
    "logging.basicConfig(\n",
    "    #filename='',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Verzeichnisse der Datensätze\n",
    "parquet_verzeichnis_ids17 = '../01_Datensaetze/improved_cic-ids-2017/ids17_parquet'\n",
    "parquet_verzeichnis_ids18 = '../01_Datensaetze/improved_cse-cic-ids-2018/ids18_parquet'\n",
    "\n",
    "# Hyperparameter Tuning durchführen\n",
    "hyperparameter_tuning = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden von IDS18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids18 Datensatz einlesen für Training 80%, Validierung 10% und Test 10%\n",
    "ids18 = pd.read_parquet(os.path.join(parquet_verzeichnis_ids18 + '_prep_0'))\n",
    "print(\"Class distribution\\n{}\".format(ids18.Label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids18.shape)\n",
    "print(ids18.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trennen von Features und Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ids18.iloc[:, :-1]  # Alle Spalten außer der letzten\n",
    "print(f\"Form von X: {X.shape}\")\n",
    "y = ids18.iloc[:, -1]   # Die letzte Spalte\n",
    "print(f\"Form von y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding für y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Einzigartige Labels: {label_encoder.classes_}\")\n",
    "print(f\"Kodierte Labels: {np.unique(y_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skallierung von X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Form von X: {X.shape}\")\n",
    "print(f\"Form von X_scaled: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilen der Daten in Trainings- und Testdatensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und temporären Datensatz\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.20, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"Form von X_train: {X_train.shape}\")\n",
    "print(f\"Form von X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überprüfen der Klassenverteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(y, dataset_name):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    total = len(y)\n",
    "    print(f\"Klassenverteilung in {dataset_name}:\")\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Klasse {cls}: {count} Beispiele ({(count/total)*100:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "print_class_distribution(y_train, \"Trainingsdatensatz\")\n",
    "print_class_distribution(y_test, \"Testdatensatz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionales Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameter_tuning:\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(\n",
    "        random_state=42), \n",
    "        param_grid, \n",
    "        cv=2, \n",
    "        scoring='accuracy', \n",
    "        n_jobs=24, \n",
    "        verbose=10)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    logging.info(f\"Beste Hyperparameter: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "logging.info(f\"Beste Hyperparameter: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mit festen Parametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hyperparameter_tuning:\n",
    "    best_model = SVC(C=1, gamma='auto', kernel='poly', random_state=42)\n",
    "    best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluierung des Modells auf dem Testdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "logging.info(f\"Test-Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "logging.info(\"\\nTest Classification Report:\\n\" + test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klassifikationsbericht und eine Konfusionsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifikationsbericht\n",
    "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Konfusionsmatrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Vorhergesagte Klasse')\n",
    "plt.ylabel('Wahre Klasse')\n",
    "plt.title('Konfusionsmatrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speichern des Modells und der Vorverarbeitungsschritte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(best_model, 'svm_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
